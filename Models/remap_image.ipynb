{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision import transforms, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "#multiply the std\n",
    "#add the mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessing = transforms.Compose([\n",
    "    transforms.Resize((100,100)),\n",
    "    transforms.CenterCrop((100,100)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image=\"gg-l2/computer/full_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = datasets.ImageFolder(root=style,\n",
    "                                           transform=preprocessing)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.utils.data.DataLoader(style, batch_size=10,\n",
    "                                              shuffle=False, num_workers=2)\n",
    "dataiter = iter(test_data)\n",
    "images, labels = dataiter.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer=images[0][0]*torch.tensor([.229])+torch.tensor([.485])\n",
    "second_layer=images[0][1]*torch.tensor([.224])+torch.tensor([.456])\n",
    "third_layer=images[0][2]*torch.tensor([.225])+torch.tensor([.406])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.imshow(image)\n",
    "    #plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "style_loss_on=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=model.FullSet(vgg.res[20],res.conv[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (range(20000)):\n",
    "    optimizer.zero_grad() \n",
    "    images=model.get_current_img()\n",
    "    input_img=rand(images)\n",
    "    current=torch.autograd.Variable(input_img,requires_grad=True)\n",
    "    output = model.forward(current)\n",
    "    \n",
    "    \n",
    "    if (style_loss_on):\n",
    "        content = ct_model.get()\n",
    "        style = st_model.get()\n",
    "        sty.optimizer.zero_grad()\n",
    "        print ('Epoch: ' + str(epoch))\n",
    "        con,sty, tot = 0, 0, 0\n",
    "        layer_num = 0\n",
    "        \n",
    "        \n",
    "        for lay in sty.dev:\n",
    "            if type(lay) == nn.Ct:\n",
    "              lay = nn.Conv(inplace=False)\n",
    "            \n",
    "            content = lay(content)\n",
    "            style = lay(style)\n",
    "            output = lay(output)\n",
    "            if type(lay) == nn.Conv2d:\n",
    "              if layer_num in style_model.content_layers:\n",
    "                content_loss = content + style.loss(style_model.content_loss_weight * output, st.ct_loss)\n",
    "                    \n",
    "        \n",
    "            l_t = l_t + 3\n",
    "            input_img=images[0][0].view(100*100)\n",
    "    \n",
    "    output_img=images[0][0].view(100*100)\n",
    "    \n",
    "    #output_img2=images[1][0].view(100*100)\n",
    "    \n",
    "    loss = F.mse_loss(output, output_img)\n",
    "    \n",
    "   # loss = .5/float(i+1)*F.mse_loss(output, output_img2) # use negative log likelihood to determine loss\n",
    "    \n",
    "   # total_loss=loss+loss2\n",
    "    loss.backward() # backward pass of network (calculate sum of gradients for graph)\n",
    "    \n",
    "    optimizer.step() # perform model perameter update (update weights)\n",
    "    if i%view_size==0:\n",
    "        \n",
    "        show_image(output.view((100,100)).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "img_math=images[2][1].view(100*100).detach().numpy().reshape(10000,1).T\n",
    "\n",
    "weight_math=list(model.children())[0].weight.detach().numpy()\n",
    "show_image(np.dot(img_math,weight_math).reshape(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img=images[2][1].view(100*100)\n",
    "output = model.forward(input_img)\n",
    "\n",
    "show_image(output.view((100,100)).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(images[4][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
